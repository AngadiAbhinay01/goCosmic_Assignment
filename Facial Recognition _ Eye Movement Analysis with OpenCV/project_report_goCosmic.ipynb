{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52880c6e",
   "metadata": {},
   "source": [
    "# AI Intern Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915ec33",
   "metadata": {},
   "source": [
    "## Angadi Abhinay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7a322",
   "metadata": {},
   "source": [
    "### Step-1: Taking a photograph using laptop/desktop camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79bb713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "def capture_photo():\n",
    "    # Open the camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Checking if the camera is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Camera not found.\")\n",
    "        return\n",
    "\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Checking if the frame is captured successfully\n",
    "    if ret:\n",
    "        # Saving the captured frame as an image\n",
    "        cv2.imwrite(\"captured_photo.jpg\", frame)\n",
    "        print(\"Photo captured and saved as 'captured_photo.jpg'.\")\n",
    "\n",
    "        # Displaying the captured image\n",
    "        cv2.imshow(\"Captured Photo\", frame)\n",
    "        cv2.waitKey(0)  \n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # Analyzing the face in the photograph\n",
    "        face_descriptor, face_landmarks = analyze_face(frame)\n",
    "\n",
    "        # Starting video recording with face and eye movement analysis\n",
    "        record_video(face_descriptor, face_landmarks)\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Unable to capture a photo.\")\n",
    "\n",
    "    # at end stop the camera\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d4b0f",
   "metadata": {},
   "source": [
    "### Step-2: Analysing the face in the photograph (Throw an error if face is not found in photograph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beb1ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_face(image):\n",
    "    # using the pre-trained cascade face detection classifier\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Converting the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detecting faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        # Use the first face for simplicity\n",
    "        (x, y, w, h) = faces[0]\n",
    "\n",
    "        # Extracting the face for region of interest\n",
    "        face_roi = gray_image[y:y+h, x:x+w]\n",
    "\n",
    "        # Loading the shape predictor model\n",
    "        shape_predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "        # Using dlib for facial landmarks\n",
    "        shape = shape_predictor(image, dlib.rectangle(x, y, x+w, y+h))\n",
    "        face_landmarks = np.array([(shape.part(i).x, shape.part(i).y) for i in range(68)])\n",
    "\n",
    "        # Using dlib for face recognition\n",
    "        face_recognizer = dlib.face_recognition_model_v1(\"dlib_face_recognition_resnet_model_v1.dat\")\n",
    "        face_descriptor = face_recognizer.compute_face_descriptor(image, shape)\n",
    "\n",
    "        return face_descriptor, face_landmarks\n",
    "\n",
    "    else:\n",
    "        print(\"Error: No face found in the photograph.\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da97ee",
   "metadata": {},
   "source": [
    "### Step-3: Next, video recording will start, match the photo and the face in the video continuously until the video recording stops. If the face does not match with the photo, throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bc9e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_video(reference_face_descriptor, reference_face_landmarks):\n",
    "    # Open the default camera for video recording\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Checking if the camera is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Camera not found.\")\n",
    "        return\n",
    "\n",
    "    # Defining the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('output_video.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "    while True:\n",
    "        # Reading a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Analyzing the face and eye movement in the video frame\n",
    "        current_face_descriptor, current_face_landmarks = analyze_face(frame)\n",
    "\n",
    "        # Checking if face is found in the current frame\n",
    "        if current_face_descriptor is not None:\n",
    "            # Comparing the current face with the reference face\n",
    "            match = compare_faces(reference_face_descriptor, current_face_descriptor)\n",
    "\n",
    "            # If the faces do not match, throw an error\n",
    "            if not match:\n",
    "                print(\"Error: Face in the video does not match the reference face.\")\n",
    "                break\n",
    "\n",
    "            # Analyzing eye movement\n",
    "            analyze_eye_movement(reference_face_landmarks, current_face_landmarks, frame)\n",
    "\n",
    "        # Writing the frame to the output video\n",
    "        out.write(frame)\n",
    "\n",
    "        # Displaying the frame\n",
    "        cv2.imshow('Video Recording', frame)\n",
    "\n",
    "        # stop the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Releasing everything when done\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b16f4b",
   "metadata": {},
   "source": [
    "### Step 4: Analyse eye movement in the video, whether he is looking into the screen or outside the screen. When he is looking outside the screen, throw a warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be97683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo captured and saved as 'captured_photo.jpg'.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n",
      "Error: No face found in the photograph.\n"
     ]
    }
   ],
   "source": [
    "def compare_faces(reference_face_descriptor, current_face_descriptor, threshold=0.6):\n",
    "    # Convert face descriptors to NumPy arrays\n",
    "    reference_np = np.array(reference_face_descriptor)\n",
    "    current_np = np.array(current_face_descriptor)\n",
    "\n",
    "    # Compare face descriptors using Euclidean distance\n",
    "    distance = np.linalg.norm(reference_np - current_np)\n",
    "\n",
    "    # Determine if the faces match based on the threshold\n",
    "    return distance < threshold\n",
    "\n",
    "def analyze_eye_movement(reference_landmarks, current_landmarks, frame):\n",
    "    # Indices of eye landmarks\n",
    "    left_eye_indices = [36, 37, 38, 39, 40, 41]\n",
    "    right_eye_indices = [42, 43, 44, 45, 46, 47]\n",
    "\n",
    "    # Extract coordinates of eye landmarks\n",
    "    left_eye_ref = reference_landmarks[left_eye_indices]\n",
    "    right_eye_ref = reference_landmarks[right_eye_indices]\n",
    "    left_eye_current = current_landmarks[left_eye_indices]\n",
    "    right_eye_current = current_landmarks[right_eye_indices]\n",
    "\n",
    "    # Calculate the average position of the eyes in the reference frame\n",
    "    avg_left_eye_ref = np.mean(left_eye_ref, axis=0)\n",
    "    avg_right_eye_ref = np.mean(right_eye_ref, axis=0)\n",
    "\n",
    "    # Calculate the average position of the eyes in the current frame\n",
    "    avg_left_eye_current = np.mean(left_eye_current, axis=0)\n",
    "    avg_right_eye_current = np.mean(right_eye_current, axis=0)\n",
    "\n",
    "    # Calculate the distance between the average eye positions\n",
    "    distance_ref = np.linalg.norm(avg_left_eye_ref - avg_right_eye_ref)\n",
    "    distance_current = np.linalg.norm(avg_left_eye_current - avg_right_eye_current)\n",
    "\n",
    "    # Set a threshold for eye movement (you may need to adjust this based on your observations)\n",
    "    eye_movement_threshold = 10.0\n",
    "\n",
    "    # Compare the distances and determine if there is significant eye movement\n",
    "    if abs(distance_current - distance_ref) > eye_movement_threshold:\n",
    "        cv2.putText(frame, \"Warning: Eyes off- the screen!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    capture_photo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991ea80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbbc05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625adc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90487f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
